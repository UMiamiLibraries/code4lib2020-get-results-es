{
  
  "0": {
    "title": "",
    "content": "404 . Page not found :( . The requested page could not be found. .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/404.html",
    "relUrl": "/404.html"
  }
  ,"1": {
    "title": "Computer Setup",
    "content": "Git . Please verify you have Git installed on your computer by running the following command in a console. . $ git --version . You should get an output like the one below depending on your operating system. . git version 2.25.0.windows.1 . If you don&#39;t have Git installed, please refer to the following documentation to install it on your computer: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git . Docker and Docker-Composer setup . In this workshop, you will need to have Docker and Docker-Composer installed on your computer. Please follow the below installation instructions from the Docker official documentation, for the operating system you are running. . Docker for Mac | Docker for Windows 10 (Pro, Enterprise, or Education) | Docker for Ubuntu | . To verify Docker is installed correctly, please run the following command on a terminal: . $ docker run hello-world . This command should output the following: . Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ . You should also verify docker-compose is intalled. Please run the following command in a terminal: . $ docker-compose --version . Depending on the version of docker-compose you have installed, the output should look like this: . $ docker-compose version 1.25.0, build 0a186604 . Increase memory for Docker . For this workshop, we need to increase the amount of memory that Docker can use in the host computer. A limit of 4096 MB should be enough. . For hosts running Mac . Open Docker settings. | Select the Advanced tab. | Increase the memory limit to 4096 MB. | Docker for Mac Advanced Settings. . . For hosts running Windows . Open Docker settings. | Select the Advanced tab. | Increase the memory limit to 4096 MB. | Docker for Windows Advanced Settings. . . For hosts running Ubuntu . Open a terminal and run the following command: | sudo sysctl -w vm.max_map_count=262144 . . Congratulations! Now you should have Docker and Docker-compose installed on your computer. In the next sections, we will go through the steps for creating a Dockerfile. . Previous: Welcome! Next: Project Setup .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/computer-setup/",
    "relUrl": "/computer-setup/"
  }
  ,"2": {
    "title": "Creating the Dockerfile",
    "content": "Creating the Dockerfile . A Dockerfile contains all the commands needed to build a specific image. Think off a Dockerfile as a recipe to build an image. . Docker images are formed by multiple read-only layers that are representations of the instructions contained in the Dockerfile. Each layer builds on top of the previous layer. . Let&#39;s create a new file named Dockerfile in the .docker directory and add the following code to it. . #.docker/Dockerfile FROM appsvc/php:7.3-apache_20200101.1 . . We are instructing Docker to start FROM the pre-existing PHP and Apache image built by Microsoft, appsvc/php:7.3-apache_20200101.1. This pre-existing image is running a Linux distribution and php version 7.3 and apache, and it was created on January 1st, 2020. . Now, let&#39;s install php composer. Add the following code to the Dockerfile. . #.docker/Dockerfile # Installing php composer RUN curl -sS https://getcomposer.org/installer | php RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version . . The pre-existing image that we are using comes with PHP Opcache enabled. This extension helps to improve PHP performance by caching scripts in memory. However, since we are going to be using this container for development purposes, we want to disable caching for now. In order to do that, let&#39;s insert the following code into our Dockerfile. . #.docker/Dockerfile #Remove php opcache file -- only for development RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini . . Synchronizing spin-up of independent containers . In this workshop we are going to have multiple containers running at the same time. However, we might run into a scenario where our development container depends on another container to work, and not only another container, but also the services running inside this other container to be up and running. . To address this problem, we are going to use wait-for-it, a bash script that will make our development container wait for any other container it depends on to continue. Add the following code to your Dockerfile: . #.docker/Dockerfile COPY ./wait-for-it/wait-for-it.sh /usr/local/wait-for-it.sh RUN chmod u+x /usr/local/wait-for-it.sh . . Adding an ENTRYPOINT to the Dockerfile . An ENTRYPOINT will let us specify which commands we want to execute when the container is started. Let&#39;s, for now, add the following code to our Dockerfile . #.docker/Dockerfile COPY ./.docker/init.sh /usr/local/bin/init.sh RUN chmod u+x /usr/local/bin/init.sh ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] . . The previous code will copy the init.sh file into the Docker container and define an ENTRYPOINT using the init.sh But wait, the init.sh file does not exist. Let&#39;s create an init.sh file in the .docker directory and add the following code to it: . #!/usr/bin/env bash echo &quot;Checking Elasticsearch node 1 is ready&quot; /usr/local/wait-for-it.sh esdata-0.local:9200 -s --timeout=120 -- echo &quot;Node 1 is ready!&quot; echo &quot;Checking Elasticsearch node 2 is ready&quot; /usr/local/wait-for-it.sh esdata-1.local:9200 -s --timeout=120 -- echo &quot;Node 2 is ready!&quot; # Install search app dependencies echo &quot;Installing search app dependencies&quot; cd /home/site/wwwroot composer install # start apache /usr/sbin/apache2ctl -D FOREGROUND . . This code will wait 2 minutes for the Elasticsearch containers (we will create these in a later section) to be ready. It will also install the search app dependencies defined in the composer.json file, and then starts up the Apache server. . The Dockerfile should look like this at this point: . FROM appsvc/php:7.3-apache_20200101.1 # Installing php composer RUN curl -sS https://getcomposer.org/installer | php RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version #Remove php opcache file -- only for development RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini COPY ./.docker/wait-for-it/wait-for-it.sh /usr/local/wait-for-it.sh RUN chmod u+x /usr/local/wait-for-it.sh COPY ./.docker/init.sh /usr/local/bin/init.sh RUN chmod u+x /usr/local/bin/init.sh ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] . . Time to build the container. Run the following code from the project root folder in a console: . $ docker build -f .docker/Dockerfile . . . The previous command tells Docker to build a container using the Dockerfile defined in the -f parameter. I f you don&#39;t specify a filepath, Docker will search for a Dockefile within the same directory the build command is executed from. The dot at the end of the command specified the location where we want to build the container. In this case, we are building the container in the current directory . The output from the previous docker build command should look similar to this: . Sending build context to Docker daemon 286.2kB Step 1/7 : FROM appsvc/php:7.2-apache_20191031.7 &gt; 692faef99277 Step 2/7 : RUN curl -sS https://getcomposer.org/installer | php &gt; Running in 59de52d7babe Cannot load Zend OPcache - it was already loaded All settings correct for using Composer Downloading... Composer (version 1.9.3) successfully installed to: /home/site/wwwroot/composer.phar Use it: php composer.phar Removing intermediate container 59de52d7babe &gt; 11c9d3ca3665 Step 3/7 : RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version &gt; Running in ea691c6d9ec2 Cannot load Zend OPcache - it was already loaded Composer version 1.9.3 2020-02-04 12:58:49 Removing intermediate container ea691c6d9ec2 &gt; 220bcb9bfeb3 Step 4/7 : RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini &gt; Running in 5b0c82733c56 Removing intermediate container 5b0c82733c56 &gt; 8bb2be6b4690 Step 5/7 : COPY ./.docker/init.sh /usr/local/bin/init.sh &gt; 51ac59253e84 Step 6/7 : RUN chmod u+x /usr/local/bin/init.sh &gt; Running in 78fd768bc949 Removing intermediate container 78fd768bc949 &gt; f0db0655f565 Step 7/7 : ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] &gt; Running in 5d6b187e36c2 Removing intermediate container 5d6b187e36c2 &gt; 67a994a34f76 Successfully built 67a994a34f76 . . So far we have written a Dockerfile to build a Docker container running PHP, Apache, php-composer and a custom ENTRYPOINT. In the next sections, we will create a docker-compose file to configure other containers that we need for our search application. . . Previous: Project Setup Next: The docker-compose file .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/creating-dockerfile/",
    "relUrl": "/creating-dockerfile/"
  }
  ,"3": {
    "title": "The docker-compose file",
    "content": "The docker-compose file . We are now ready to create our docker-compose file. Our development environment will consist of two PHP applications and a two-node Elasticsearch cluster. Let&#39;s get started. . Let&#39;s start by defining the two-node Elasticsearch cluster. Add the following code to the docker-compose.yml file at the root of the project directory. Keep in mind this is a YAML file, so indentation matters. . # docker-compose.yml services: esdata-0.local: # First Elasticsearch node container_name: esdata-0.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 # Official Elasticsearch image environment: # Specific container environment variables - node.name=esdata-0.local # Name of the Elasticsearch node - cluster.name=es-local-cluster # Name of the Elasticsearch cluster - discovery.seed_hosts=esdata-1.local #List of other nodes in the cluster that are likely to be live and contactable - cluster.initial_master_nodes=esdata-0.local # List of other nodes in the cluster that are master eligible - bootstrap.memory_lock=true # Prevents any Elasticsearch object in memory from being swapped out to the hard drive - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # Sets JVM heap size in the container volumes: # Attach local data directory - esdata-0.local.data:/usr/share/elasticsearch/data # Docker volume to persist the node data across restarts ports: - 9200:9200 # Exposing port 9200 of the container ulimits: memlock: # Sets an unlimited amount of memory to be locked by the service (container) soft: -1 hard: -1 esdata-1.local: # Second Elasticsearch node container_name: esdata-1.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 environment: - node.name=esdata-1.local - cluster.name=es-local-cluster - discovery.seed_hosts=esdata-0.local - cluster.initial_master_nodes=esdata-0.local - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; volumes: - esdata-1.local.data:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 volumes: # Defines volumes used by the services esdata-0.local.data: driver: local esdata-1.local.data: driver: local . . Let&#39;s run our cluster with Docker-Compose. Run the following command in a console in the same directory where the docker-compose file is located. . $ docker-compose up . . Docker-Compose will pull the Elasticsearch v7.6.0 image and start the two services we defined. This operation can take a few minutes depending on the host computer hardware. . Let&#39;s check if the cluster is running. Open a browser and visit the URL http://localhost:9200/_nodes/stats . We are querying the Nodes stats API of Elasticsearch. The response should look similar to this (nodes details collapsed on purpose): . { &quot;_nodes&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 2, &quot;failed&quot;: 0 }, &quot;cluster_name&quot;: &quot;es-local-cluster&quot;, &quot;nodes&quot;: { &quot;BkODnEDlS4mjSh4tg6NeTA&quot;: {}, // 20 items &quot;TTTdcluiRrSao-9vFdSpvQ&quot;: {} // 20 items } } . . Go back to the console from where you ran the docker-compose up command and press Ctrl+C to stop the containers. . So far we have defined a two-node Elasticsearch cluster. These two nodes (containers) are using the official image of Elasticsearch v7.6.0 and are part of the es-local-cluster cluster. We also defined two volumes to be used by each node, so the node data is persisted across restarts of the container. . Adding a service for our custom app . Now we have a working Elasticsearch cluster. It is time to define the other service that will run the custom app we are going to create. . Add the below service in the docker-compose file, after the second Elasticsearch service. . # docker-compose.yml search-app: # Search App service container_name: search-app build: context: ./ dockerfile: ./.docker/Dockerfile environment: # Specific container environment variables - APACHE_PORT=80 # Set Apache to listen on port 80 - APACHE_DOCUMENT_ROOT=/home/site/wwwroot/public #Set the directory from which Apache will serve files volumes: # Attach local data directory - ./search-app:/home/site/wwwroot depends_on: - esdata-0.local - esdata-1.local ports: - 8080:80 . . Run docker-compose up again and visit http://localhost:8080/public/ in your browser. You should get the following: . $ docker-compose up . . . Your docker-compose file should look like these now: . #docker-compose.yml version: &#39;3.6&#39; services: esdata-0.local: # First Elasticsearch node container_name: esdata-0.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 # Official Elasticsearch image environment: # Specific container environment variables - node.name=esdata-0.local # Name of the Elasticsearch node - cluster.name=es-local-cluster # Name of the Elasticsearch cluster - discovery.seed_hosts=esdata-1.local #List of other nodes in the cluster that are likely to be live and contactable - cluster.initial_master_nodes=esdata-0.local # List of other nodes in the cluster that are master eligible - bootstrap.memory_lock=true # Prevents any Elasticsearch object in memory from being swapped out to the hard drive - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # Sets JVM heap size in the container volumes: # Attach local data directory - esdata-0.local.data:/usr/share/elasticsearch/data # Docker volume to persist the node data across restarts ports: - 9200:9200 # Exposing port 9200 of the container ulimits: memlock: # Sets an unlimited amount of memory to be locked by the service (container) soft: -1 hard: -1 esdata-1.local: # Second Elasticsearch node container_name: esdata-1.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 environment: - node.name=esdata-1.local - cluster.name=es-local-cluster - discovery.seed_hosts=esdata-0.local - cluster.initial_master_nodes=esdata-0.local - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; volumes: - esdata-1.local.data:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 search-app: # Search App service container_name: search-app build: context: ./ dockerfile: ./.docker/Dockerfile environment: # Specific container environment variables - APACHE_PORT=80 # Set Apache to listen on port 80 - APACHE_DOCUMENT_ROOT=/home/site/wwwroot/public #Set the directory from which Apache will serve files volumes: # Attach local data directory - ./search-app:/home/site/wwwroot depends_on: - esdata-0.local - esdata-1.local ports: - 8080:80 volumes: # Defines volumes used by the services esdata-0.local.data: driver: local esdata-1.local.data: driver: local . . We now have in place all the infrastructure for our search app. Let&#39;s create the search app! . . Previous: Creating the Dockerfile Next: The search app .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/docker-compose-file/",
    "relUrl": "/docker-compose-file/"
  }
  ,"4": {
    "title": "Welcome!",
    "content": "Next: Computer Setup .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/index.html",
    "relUrl": "/index.html"
  }
  ,"5": {
    "title": "Project Setup",
    "content": "Project Setup . Let&#39;s get started with the project setup. We are going to clone a boilerplate project from GitHub. Run the following command from a console to clone the boilerplate code into your computer: . $ git clone https://github.com/UMiamiLibraries/get-results-es-boilerplate.git . . The boilerplate structure should look like this: . +-- .. |-- get-results-es-boilerplate | |-- .docker (This directory will contain our Docker related files) | | |-- wait-for-it (We will get back to this directory in future sections of the workshop) | |-- search-app (This directoy contains the files for our search app) | |-- docker-compose.yml (We will configure our application&#39;s services in this file) +-- .. . . In the next section we will start creating our Dockerfile. . Previous: Computer Setup Next: Creating the Dockerfile .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/project-setup/",
    "relUrl": "/project-setup/"
  }
  ,"6": {
    "title": "The search app",
    "content": "The search app . We are now ready to create our docker-compose file. Our development environment will consist of two PHP applications and a two-node Elasticsearch cluster. Let&#39;s get started. . Let&#39;s start by defining the two-node Elasticsearch cluster. Add the following code to the docker-compose.yml file at the root of the project directory. Keep in mind this is a YAML file, so indentation matters. . # docker-compose.yml services: esdata-0.local: # First Elasticsearch node container_name: esdata-0.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 # Official Elasticsearch image environment: # Specific container environment variables - node.name=esdata-0.local # Name of the Elasticsearch node - cluster.name=es-local-cluster # Name of the Elasticsearch cluster - discovery.seed_hosts=esdata-1.local #List of other nodes in the cluster that are likely to be live and contactable - cluster.initial_master_nodes=esdata-0.local # List of other nodes in the cluster that are master eligible - bootstrap.memory_lock=true # Prevents any Elasticsearch object in memory from being swapped out to the hard drive - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # Sets JVM heap size in the container volumes: # Attach local data directory - esdata-0.local.data:/usr/share/elasticsearch/data # Docker volume to persist the node data across restarts ports: - 9200:9200 # Exposing port 9200 of the container ulimits: memlock: # Sets an unlimited amount of memory to be locked by the service (container) soft: -1 hard: -1 esdata-1.local: # Second Elasticsearch node container_name: esdata-1.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 environment: - node.name=esdata-1.local - cluster.name=es-local-cluster - discovery.seed_hosts=esdata-0.local - cluster.initial_master_nodes=esdata-0.local - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; volumes: - esdata-1.local.data:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 volumes: # Defines volumes used by the services esdata-0.local.data: driver: local esdata-1.local.data: driver: local . . Let&#39;s run our cluster with Docker-Compose. Run the following command in a console in the same directory where the docker-compose file is located. . $ docker-compose up . . Docker-Compose will pull the Elasticsearch v7.6.0 image and start the two services we defined. This operation can take a few minutes depending on the host computer hardware. . Let&#39;s check if the cluster is running. Open a browser and visit the URL http://localhost:9200/_nodes/stats . We are querying the Nodes stats API of Elasticsearch. The response should look similar to this (nodes details collapsed on purpose): . { &quot;_nodes&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 2, &quot;failed&quot;: 0 }, &quot;cluster_name&quot;: &quot;es-local-cluster&quot;, &quot;nodes&quot;: { &quot;BkODnEDlS4mjSh4tg6NeTA&quot;: {}, // 20 items &quot;TTTdcluiRrSao-9vFdSpvQ&quot;: {} // 20 items } } . . Go back to the console from where you ran the docker-compose up command and press Ctrl+C to stop the containers. . So far we have defined a two-node Elasticsearch cluster. These two nodes (containers) are using the official image of Elasticsearch v7.6.0 and are part of the es-local-cluster cluster. We also defined two volumes to be used by each node, so the node data is persisted across restarts of the container. . Adding a service for our custom app . Now we have a working Elasticsearch cluster. It is time to define the other service that will run the custom app we are going to create. . Add the below service in the docker-compose file, after the second Elasticsearch service. . # docker-compose.yml search-app: # Search App service container_name: search-app build: context: ./ dockerfile: ./.docker/Dockerfile environment: # Specific container environment variables - APACHE_PORT=80 # Set Apache to listen on port 80 - APACHE_DOCUMENT_ROOT=/home/site/wwwroot/public #Set the directory from which Apache will serve files volumes: # Attach local data directory - ./search-app:/home/site/wwwroot depends_on: - esdata-0.local - esdata-1.local ports: - 8080:80 . . Run docker-compose up again and visit http://localhost:8080/public/ in your browser. You should get the following: . $ docker-compose up . . . We now have in place all the infrastructure for our search app. Let&#39;s create the search app! . . Previous: The docker-compose file Next: TBD .",
    "url": "http://localhost:4000/code4lib2020-get-results-es/search-app-1/",
    "relUrl": "/search-app-1/"
  }
  
}