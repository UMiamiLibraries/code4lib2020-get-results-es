{
  
  "0": {
    "title": "",
    "content": "404 . Page not found :( . The requested page could not be found. .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/404.html",
    "relUrl": "/404.html"
  }
  ,"1": {
    "title": "Computer Setup",
    "content": "Git . Please verify you have Git installed on your computer by running the following command in a console. . $ git --version . You should get an output like the one below depending on your operating system. . git version 2.25.0.windows.1 . If you don&#39;t have Git installed, please refer to the following documentation to install it on your computer: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git . Docker and Docker-Composer setup . In this workshop, you will need to have Docker and Docker-Composer installed on your computer. Please follow the below installation instructions from the Docker official documentation, for the operating system you are running. . Docker for Mac | Docker for Windows 10 (Pro, Enterprise, or Education) | Docker for Ubuntu | . To verify Docker is installed correctly, please run the following command on a terminal: . $ docker run hello-world . This command should output the following: . Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ . You should also verify docker-compose is intalled. Please run the following command in a terminal: . $ docker-compose --version . Depending on the version of docker-compose you have installed, the output should look like this: . $ docker-compose version 1.25.0, build 0a186604 . Increase memory for Docker . For this workshop, we need to increase the amount of memory that Docker can use in the host computer. A limit of 4096 MB should be enough. . For hosts running Mac . Open Docker settings. | Select the Advanced tab. | Increase the memory limit to 4096 MB. | Docker for Mac Advanced Settings. . . For hosts running Windows . Open Docker settings. | Select the Advanced tab. | Increase the memory limit to 4096 MB. | Docker for Windows Advanced Settings. . . For hosts running Ubuntu . Open a terminal and run the following command: | sudo sysctl -w vm.max_map_count=262144 . . Congratulations! Now you should have Docker and Docker-compose installed on your computer. In the next sections, we will go through the steps for creating a Dockerfile. . Previous: Welcome! Next: Project Setup .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/computer-setup/",
    "relUrl": "/computer-setup/"
  }
  ,"2": {
    "title": "Creating the Dockerfile",
    "content": "Creating the Dockerfile . A Dockerfile contains all the commands needed to build a specific image. Think of a Dockerfile as a recipe to build an image. . Docker images are formed by multiple read-only layers that are representations of the instructions contained in the Dockerfile. Each layer builds on top of the previous layer. . Let&#39;s create a new file named Dockerfile in the .docker directory and add the following code to it. . #.docker/Dockerfile FROM appsvc/php:7.3-apache_20200101.1 . . We are instructing Docker to start FROM the pre-existing PHP and Apache image built by Microsoft, appsvc/php:7.3-apache_20200101.1. This pre-existing image is running a Linux distribution and php version 7.3 and apache, and it was created on January 1st, 2020. . Now, let&#39;s install php composer. Add the following code to the Dockerfile. . #.docker/Dockerfile # Installing php composer RUN curl -sS https://getcomposer.org/installer | php RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version . . The pre-existing image that we are using comes with PHP Opcache enabled. This extension helps to improve PHP performance by caching scripts in memory. However, since we are going to be using this container for development purposes, we want to disable caching for now. In order to do that, let&#39;s insert the following code into our Dockerfile. . #.docker/Dockerfile #Remove php opcache file -- only for development RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini . . Synchronizing spin-up of independent containers . In this workshop we are going to have multiple containers running at the same time. However, we might run into a scenario where our development container depends on another container to work, and not only another container, but also the services running inside this other container to be up and running. . To address this problem, we are going to use wait-for-it, a bash script that will make our development container wait for any other container it depends on to continue. Add the following code to your Dockerfile: . #.docker/Dockerfile COPY ./.docker/wait-for-it/wait-for-it.sh /usr/local/wait-for-it.sh RUN chmod u+x /usr/local/wait-for-it.sh . . Adding an ENTRYPOINT to the Dockerfile . An ENTRYPOINT will let us specify which commands we want to execute when the container is started. Let&#39;s, for now, add the following code to our Dockerfile . #.docker/Dockerfile COPY ./.docker/init.sh /usr/local/bin/init.sh RUN chmod u+x /usr/local/bin/init.sh ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] . . The previous code will copy the init.sh file into the Docker container and define an ENTRYPOINT using the init.sh But wait, the init.sh file does not exist. Let&#39;s create an init.sh file in the .docker directory and add the following code to it: . #!/usr/bin/env bash echo &quot;Checking Elasticsearch node 1 is ready&quot; /usr/local/wait-for-it.sh esdata-0.local:9200 -s --timeout=120 -- echo &quot;Node 1 is ready!&quot; echo &quot;Checking Elasticsearch node 2 is ready&quot; /usr/local/wait-for-it.sh esdata-1.local:9200 -s --timeout=120 -- echo &quot;Node 2 is ready!&quot; # Install search app dependencies echo &quot;Installing search app dependencies&quot; cd /home/site/wwwroot composer install # start apache /usr/sbin/apache2ctl -D FOREGROUND . . This code will wait 2 minutes for the Elasticsearch containers (we will create these in a later section) to be ready. It will also install the search app dependencies defined in the composer.json file, and then starts up the Apache server. . The Dockerfile should look like this at this point: . FROM appsvc/php:7.3-apache_20200101.1 # Installing php composer RUN curl -sS https://getcomposer.org/installer | php RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version #Remove php opcache file -- only for development RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini COPY ./.docker/wait-for-it/wait-for-it.sh /usr/local/wait-for-it.sh RUN chmod u+x /usr/local/wait-for-it.sh COPY ./.docker/init.sh /usr/local/bin/init.sh RUN chmod u+x /usr/local/bin/init.sh ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] . . Time to build the container. Run the following code from the project root folder in a console: . $ docker build -f .docker/Dockerfile -t search-app:v1.0.0 . . . The previous command tells Docker to build a container using the Dockerfile defined in the -f parameter. If you don&#39;t specify a filepath, Docker will search for a Dockefile within the same directory the build command is executed from. We are also tagging the Docker container by using the -t parameter. The dot at the end of the command specified the location where we want to build the container. In this case, we are building the container in the current directory. . The output from the previous docker build command should look similar to this: . Sending build context to Docker daemon 286.2kB Step 1/7 : FROM appsvc/php:7.2-apache_20191031.7 &gt; 692faef99277 Step 2/7 : RUN curl -sS https://getcomposer.org/installer | php &gt; Running in 59de52d7babe Cannot load Zend OPcache - it was already loaded All settings correct for using Composer Downloading... Composer (version 1.9.3) successfully installed to: /home/site/wwwroot/composer.phar Use it: php composer.phar Removing intermediate container 59de52d7babe &gt; 11c9d3ca3665 Step 3/7 : RUN mv composer.phar /usr/local/bin/composer &amp;&amp; chmod +x /usr/local/bin/composer &amp;&amp; composer --version &gt; Running in ea691c6d9ec2 Cannot load Zend OPcache - it was already loaded Composer version 1.9.3 2020-02-04 12:58:49 Removing intermediate container ea691c6d9ec2 &gt; 220bcb9bfeb3 Step 4/7 : RUN rm -rf /usr/local/etc/php/conf.d/opcache-recommended.ini &gt; Running in 5b0c82733c56 Removing intermediate container 5b0c82733c56 &gt; 8bb2be6b4690 Step 5/7 : COPY ./.docker/init.sh /usr/local/bin/init.sh &gt; 51ac59253e84 Step 6/7 : RUN chmod u+x /usr/local/bin/init.sh &gt; Running in 78fd768bc949 Removing intermediate container 78fd768bc949 &gt; f0db0655f565 Step 7/7 : ENTRYPOINT [&quot;/usr/local/bin/init.sh&quot;] &gt; Running in 5d6b187e36c2 Removing intermediate container 5d6b187e36c2 &gt; 67a994a34f76 Successfully built 67a994a34f76 . . So far we have written a Dockerfile to build a Docker container running PHP, Apache, php-composer and a custom ENTRYPOINT. In the next sections, we will create a docker-compose file to configure other containers that we need for our search application. . . Previous: Project Setup Next: The docker-compose file .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/creating-dockerfile/",
    "relUrl": "/creating-dockerfile/"
  }
  ,"3": {
    "title": "The Dev Tools Console",
    "content": "The Dev Tools Console . Kibana is an open source data visualization dashboard for Elasticsearch. The Dev Tools Console is one of the many tools that Kibana offers to manage your Elasticsearch data. . First, let&#39;s add a Kibana service to our docker-compose file. Be sure to stop docker-compose by pressing Ctrl+C in the console where you are running docker-compose or run &#39;docker-compose stop&#39; from a new console. . Add the following code to the services section of the docker-compose file: . kibana: image: docker.elastic.co/kibana/kibana:7.6.1 environment: ELASTICSEARCH_HOSTS: http://esdata-0.local:9200 ports: - 5601:5601 # Exposing port 5601 of the container . . We are defining a kibana service using the official Kibana Docker image. We are also defining the esdata-0.local node as the host that Kibana will connect to. The port 5601 is exposed to access Kibana from our browser. . Run docker-compose up from a console. This operation can take a few minutes depending on the host computer hardware. . $ docker-compose up . . When all of the services are running, open http://localhost:5601/ in your browser. You should see the Kibana homepage: . Click the Console link under Manage and Administer the Elastic Stack . You should see the Dev Tools . You can use the console to interact with the data in your cluster directly. . . Previous: Searching multiple indexes Next: Useful links .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/dev-tools-console/",
    "relUrl": "/dev-tools-console/"
  }
  ,"4": {
    "title": "The docker-compose file",
    "content": "The docker-compose file . We are now ready to create our docker-compose file. Our development environment will consist of two PHP applications and a two-node Elasticsearch cluster. Let&#39;s get started. . Let&#39;s start by defining the two-node Elasticsearch cluster. Add the following code to the docker-compose.yml file at the root of the project directory. Keep in mind this is a YAML file, so indentation matters. . # docker-compose.yml services: esdata-0.local: # First Elasticsearch node container_name: esdata-0.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 # Official Elasticsearch image environment: # Specific container environment variables - node.name=esdata-0.local # Name of the Elasticsearch node - cluster.name=es-local-cluster # Name of the Elasticsearch cluster - discovery.seed_hosts=esdata-1.local #List of other nodes in the cluster that are likely to be live and contactable - cluster.initial_master_nodes=esdata-0.local # List of other nodes in the cluster that are master eligible - bootstrap.memory_lock=true # Prevents any Elasticsearch object in memory from being swapped out to the hard drive - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # Sets JVM heap size in the container volumes: # Attach local data directory - esdata-0.local.data:/usr/share/elasticsearch/data # Docker volume to persist the node data across restarts ports: - 9200:9200 # Exposing port 9200 of the container ulimits: memlock: # Sets an unlimited amount of memory to be locked by the service (container) soft: -1 hard: -1 esdata-1.local: # Second Elasticsearch node container_name: esdata-1.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 environment: - node.name=esdata-1.local - cluster.name=es-local-cluster - discovery.seed_hosts=esdata-0.local - cluster.initial_master_nodes=esdata-0.local - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; volumes: - esdata-1.local.data:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 volumes: # Defines volumes used by the services esdata-0.local.data: driver: local esdata-1.local.data: driver: local . . Let&#39;s run our cluster with Docker-Compose. Run the following command in a console in the same directory where the docker-compose file is located. . $ docker-compose up . . Docker-Compose will pull the Elasticsearch v7.6.0 image and start the two services we defined. This operation can take a few minutes depending on the host computer hardware. . Let&#39;s check if the cluster is running. Open a browser and visit the URL http://localhost:9200/_nodes/stats . We are querying the Nodes stats API of Elasticsearch. The response should look similar to this (nodes details collapsed on purpose): . { &quot;_nodes&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 2, &quot;failed&quot;: 0 }, &quot;cluster_name&quot;: &quot;es-local-cluster&quot;, &quot;nodes&quot;: { &quot;BkODnEDlS4mjSh4tg6NeTA&quot;: {}, // 20 items &quot;TTTdcluiRrSao-9vFdSpvQ&quot;: {} // 20 items } } . . Go back to the console from where you ran the docker-compose up command and press Ctrl+C to stop the containers. . So far we have defined a two-node Elasticsearch cluster. These two nodes (containers) are using the official image of Elasticsearch v7.6.0 and are part of the es-local-cluster cluster. We also defined two volumes to be used by each node, so the node data is persisted across restarts of the container. . Adding a service for our custom app . Now we have a working Elasticsearch cluster. It is time to define the other service that will run the custom app we are going to create. . Add the below service in the docker-compose file, after the second Elasticsearch service. . # docker-compose.yml search-app: # Search App service container_name: search-app build: context: ./ dockerfile: ./.docker/Dockerfile environment: # Specific container environment variables - APACHE_PORT=80 # Set Apache to listen on port 80 - APACHE_DOCUMENT_ROOT=/home/site/wwwroot/public #Set the directory from which Apache will serve files volumes: # Attach local data directory - ./search-app:/home/site/wwwroot depends_on: - esdata-0.local - esdata-1.local ports: - 8080:80 . . Run docker-compose up again and visit http://localhost:8080/public/ in your browser. You should get the following: . $ docker-compose up . . . Your docker-compose file should look like these now: . #docker-compose.yml version: &#39;3.6&#39; services: esdata-0.local: # First Elasticsearch node container_name: esdata-0.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 # Official Elasticsearch image environment: # Specific container environment variables - node.name=esdata-0.local # Name of the Elasticsearch node - cluster.name=es-local-cluster # Name of the Elasticsearch cluster - discovery.seed_hosts=esdata-1.local #List of other nodes in the cluster that are likely to be live and contactable - cluster.initial_master_nodes=esdata-0.local # List of other nodes in the cluster that are master eligible - bootstrap.memory_lock=true # Prevents any Elasticsearch object in memory from being swapped out to the hard drive - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # Sets JVM heap size in the container volumes: # Attach local data directory - esdata-0.local.data:/usr/share/elasticsearch/data # Docker volume to persist the node data across restarts ports: - 9200:9200 # Exposing port 9200 of the container ulimits: memlock: # Sets an unlimited amount of memory to be locked by the service (container) soft: -1 hard: -1 esdata-1.local: # Second Elasticsearch node container_name: esdata-1.local image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0 environment: - node.name=esdata-1.local - cluster.name=es-local-cluster - discovery.seed_hosts=esdata-0.local - cluster.initial_master_nodes=esdata-0.local - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; volumes: - esdata-1.local.data:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 search-app: # Search App service container_name: search-app build: context: ./ dockerfile: ./.docker/Dockerfile environment: # Specific container environment variables - APACHE_PORT=80 # Set Apache to listen on port 80 - APACHE_DOCUMENT_ROOT=/home/site/wwwroot/public #Set the directory from which Apache will serve files volumes: # Attach local data directory - ./search-app:/home/site/wwwroot depends_on: - esdata-0.local - esdata-1.local ports: - 8080:80 volumes: # Defines volumes used by the services esdata-0.local.data: driver: local esdata-1.local.data: driver: local . . We now have in place all the infrastructure for our search app. Let&#39;s create the search app! . . Previous: Creating the Dockerfile Next: The search app (part 1) .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/docker-compose-file/",
    "relUrl": "/docker-compose-file/"
  }
  ,"5": {
    "title": "Welcome!",
    "content": "Welcome to the Code4Lib 2020 pre-conference workshop Get results! with Elasticsearch. I hope you find the workshop useful and you learn something new today. Let&#39;s get started! . Next: Computer Setup .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/index.html",
    "relUrl": "/index.html"
  }
  ,"6": {
    "title": "Project Setup",
    "content": "Project Setup . Let&#39;s get started with the project setup. We are going to clone a boilerplate project from GitHub. Run the following command from a console to clone the boilerplate code into your computer: . $ git clone https://github.com/UMiamiLibraries/get-results-es-boilerplate.git . . We have a Git submodule in our project. It is located in the .docker/wait-for-it directory. We need to initialize the submodule and update it. First, let&#39;s run the following command in the console: . $ git submodule init . . The previous command initialises the submodule. Next, we have to update it. Run the following code: . $ git submodule update . . Now we have initialized the Git submodule in our project. . At this point, the boilerplate structure should look like this: . +-- .. |-- get-results-es-boilerplate | |-- .docker (This directory will contain our Docker related files) | | |-- wait-for-it (We will get back to this directory in future sections of the workshop) | |-- search-app (This directoy contains the files for our search app) | |-- docker-compose.yml (We will configure our application&#39;s services in this file) +-- .. . . In the next section we will start creating our Dockerfile. . . Previous: Computer Setup Next: Creating the Dockerfile .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/project-setup/",
    "relUrl": "/project-setup/"
  }
  ,"7": {
    "title": "The search app (part 1)",
    "content": "The search app (part 1) . In this workshop we will be working with National Screening Room collection (https://www.loc.gov/collections/national-screening-room/) from the Library of Congress. You can find more information about this collection here. . We will ingest data from this collection into our Elasticsearch cluster. Then, we will use our application to find items in our cluster from this collection. . The API from the Library of Congress is still a work in progress. The Beta documentation can be found here. According to the documentation, we can the collection in JSON format by appending ?fo=json to the URL of the collection. . If you open https://www.loc.gov/collections/national-screening-room/?fo=json in your browser you will get the JSON of this collection. . A custom command to ingest the collection’s data into the Elasticsearch cluster . The search-app directory contains the Symfony app that will query our Elasticsearch cluster. But first, we need a way to ingest data from the Library of Congress&#39; collection into our cluster. . Navigate to /search-app/src/Command. This directory contains a class named ElasticsearchIngesterCommand. The class defines custom Symfony command that will ingest data into our Elasticsearch cluster. Let&#39;s give it a look. . Our class extends the Command class of Symfony and overrides the configure() and execute() functions. . # search-app/src/CustomScripts/ElasticsearchIngesterCommand.php ... class ElasticsearchIngesterCommand extends Command { protected static $defaultName = &#39;app:ingest-data&#39;; private $elasticSearchClient; private $outputInterface; private $apiUrl; private $indexName; public function __construct() { $elastic_host_info = [ $_ENV[&#39;ELASTIC_HOST&#39;], $_ENV[&#39;ELASTIC_PORT&#39;], $_ENV[&#39;ELASTIC_USER&#39;], $_ENV[&#39;ELASTIC_PASSWORD&#39;] ]; $this-&gt;elasticSearchClient = ClientBuilder::create()-&gt;setHosts($elastic_host_info)-&gt;build(); parent::__construct(); } protected function configure() { $this-&gt;setDescription(&#39;Ingests data from a LOC Collection API into an Elasticsearch cluster&#39;) -&gt;addArgument(&#39;apiUrl&#39;, InputArgument::REQUIRED, &#39;Pass API Url&#39;) -&gt;addArgument(&#39;indexName&#39;, InputArgument::REQUIRED, &#39;Pass the index name&#39;); } protected function execute(InputInterface $input, OutputInterface $output) { $this-&gt;outputInterface = $output; $this-&gt;apiUrl = $input-&gt;getArgument(&#39;apiUrl&#39;); $this-&gt;indexName = $input-&gt;getArgument(&#39;indexName&#39;); $output-&gt;writeln(&#39;Checking if index exists...&#39;); if (!$this-&gt;indexExists()) { $output-&gt;writeln(&#39;Creating index &#39; . $this-&gt;indexName); $this-&gt;createIndex(); } $this-&gt;ingestData(); return 0; } .... } . . In the class constructor we are building an Elasticsearch client using the official PHP client for Elasticsearch. The Elasticsearch settings are stored in the .env file . # search-app/.env ELASTIC_HOST=esdata-0.local ELASTIC_PORT=9200 ELASTIC_USER=elastic ELASTIC_PASSWORD=changeme . . The ELASTIC_HOST value corresponds to the Elastisearch master node we defined in the docker-compose file. All the interactions made by the PHP client for Elasticsearch will be done using port 9200. The ELASTIC_USER and ELASTIC_PASSWORD values are the default values. IMPORTANT: These values should be changed when using Elasticsearch in a production environment . There are also a couple of functions in the class that are responsible for getting the JSON data from the Library of Congress API, check if a specific index in Elasticseach exists and create an index in Elasticsearch. . # search-app/src/CustomScripts/ElasticsearchIngester.php ... private function getJsonData($url) { sleep(1); //We are waiting a second between each API call to prevent being temporarily banned // by the Library of Congress API $json = file_get_contents($url); return json_decode($json); } public function indexExists() { $indexParams[&#39;index&#39;] = $this-&gt;indexName; return $this-&gt;elasticSearchClient-&gt;indices()-&gt;exists($indexParams); } public function createIndex() { $params = [ &#39;index&#39; =&gt; $this-&gt;indexName ]; $this-&gt;elasticSearchClient-&gt;indices()-&gt;create($params); } ... . . The ingestData() function deals with ingesting the data into the Elasticsearch cluster. The function goes through all the items in the collection and gets the id, title, location, online_format, url, notes, image_url and description of each one. . # search-app/src/CustomScripts/ElasticsearchIngester.php ... private function ingestData() { $this-&gt;outputInterface-&gt;writeln(&#39;Ingesting data&#39;); $progressBar = new ProgressBar($this-&gt;outputInterface, 100); $currentApiUrl = $this-&gt;apiUrl; do { $data = $this-&gt;getJsonData($currentApiUrl); if ($data) { $results = $data-&gt;results; $pagination = $data-&gt;pagination; $params = $this-&gt;prepareValues($results); $this-&gt;elasticSearchClient-&gt;bulk($params); $progressBar-&gt;advance(4); $currentApiUrl = !empty($pagination-&gt;next) ? $pagination-&gt;next : null; } } while (!empty($currentApiUrl)); $progressBar-&gt;finish(); $this-&gt;outputInterface-&gt;writeln( PHP_EOL . &#39;Finished ingesting data&#39;); } private function prepareValues($results) { $params = [&#39;body&#39; =&gt; []]; foreach ($results as $result) { $params[&#39;body&#39;][] = [ &#39;index&#39; =&gt; [ &#39;_index&#39; =&gt; $this-&gt;indexName, &#39;_id&#39; =&gt; $result-&gt;id ] ]; $params[&#39;body&#39;][] = [ &#39;title&#39; =&gt; isset($result-&gt;title) ? $result-&gt;title : &#39;&#39;, &#39;online_format&#39; =&gt; isset($result-&gt;online_format) ? $result-&gt;online_format : &#39;&#39;, &#39;location&#39; =&gt; isset($result-&gt;location) ? $result-&gt;location : &#39;&#39;, &#39;url&#39; =&gt; isset($result-&gt;url) ? $result-&gt;url : &#39;&#39;, &#39;notes&#39; =&gt; isset($result-&gt;item-&gt;notes) ? $result-&gt;item-&gt;notes : &#39;&#39;, &#39;image_url&#39; =&gt; isset($result-&gt;image_url) ? $result-&gt;image_url : &#39;&#39;, &#39;description&#39; =&gt; isset($result-&gt;description) ? $result-&gt;description : &#39;&#39; ]; } return $params; } ... . . Now that we are familiar with the custom command to ingest the collection&#39;s data into the Elasticsearch cluster, let&#39;s run it! . Running the command to ingest the collection’s data into the Elasticsearch cluster . We have to run the command from within the search-app Docker container. We can do this by executing an interactive bash shell inside the container. Before executing the following code from a console, please be sure that the containers are running. . docker exec -it search-app bash . . Your console should display something similar to this: . root@19c1aaf68884:/home# . . Every command we run now is executed from within the container. Let&#39;s switch to the root directory of the Symfony app and run the custom command. Run the following two commands: . . $ cd site/wwwroot/ $ php bin/console app:ingest-data &#39;https://www.loc.gov/collections/national-screening-room/?fo=json&#39; &#39;screening-room-index&#39; . . The output should look similar to this: . Cannot load Zend OPcache - it was already loaded Checking if index exists... Ingesting data 100/100 [============================] 100% Finished ingesting data . . If you visit http://localhost:9200/_search/?pretty in your browser, you should get a response from Elasticsearch with 10 items from the index we just created. . Now we have an Elasticsearch cluster with data. Time to begin querying this data from our Symfony app . . Previous: The docker-compose file Next: The search app (part 2) .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/search-app-1/",
    "relUrl": "/search-app-1/"
  }
  ,"8": {
    "title": "The search app (part 2)",
    "content": "The search app (part 2) . Let&#39;s start by defining the SearchController in our Symfony app . The SearchController class currently have a defined route for the root URL of our application. This route calls the index() function which returns a twig template. We get this when visiting the following URL http://localhost:8080/public/ . . Let&#39;s modify the controller class so we can do a search. Replace the index() function with the following one. Be sure to import all the required classes. . # search-app/src/Controller/SearchController.php /** * @Route(&quot;/&quot;) */ public function index(Request $request) { $searchTerm = $request-&gt;query-&gt;get(&#39;query&#39;); $searchResults = []; if ($searchTerm) { $queryResponse = $this-&gt;doSearch($searchTerm); $searchResults = $queryResponse[&#39;hits&#39;][&#39;hits&#39;]; } return $this-&gt;render(&#39;search-app.html.twig&#39;, [ &#39;searchTerm&#39; =&gt; $searchTerm, &#39;searchResults&#39; =&gt; $searchResults ]); } . . The index() function will render a twig template with the results from our query. We need to define the doSearch() auxiliary function that is being called from the index() function. Add the following code below the index() function: . # search-app/src/Controller/SearchController.php private function doSearch($searchTerm) { $elastic_host_info = [ $_ENV[&#39;ELASTIC_HOST&#39;], $_ENV[&#39;ELASTIC_PORT&#39;] ]; $elasticSearchClient = ClientBuilder::create()-&gt;setHosts($elastic_host_info)-&gt;build(); $searchParams[&#39;index&#39;] = &#39;screening-room-index&#39;; // which index to search $searchParams[&#39;body&#39;][&#39;query&#39;][&#39;simple_query_string&#39;][&#39;query&#39;] = $searchTerm; // what to search for return $elasticSearchClient-&gt;search($searchParams); } . . In the doSearch() function, we initialize an Elasticsearch client (using the values stored in the .env file) and then we prepare a simple query string query and return the results. . At this point, your SearchController class should look like this: . # search-app/src/Controller/SearchController.php namespace App Controller; use Elasticsearch ClientBuilder; use Symfony Bundle FrameworkBundle Controller AbstractController; use Symfony Component HttpFoundation Request; use Symfony Component Routing Annotation Route; class SearchController extends AbstractController { /** * @Route(&quot;/&quot;) */ public function index(Request $request) { $searchTerm = $request-&gt;query-&gt;get(&#39;query&#39;); $searchResults = []; if ($searchTerm) { $queryResponse = $this-&gt;doSearch($searchTerm); $searchResults = $queryResponse[&#39;hits&#39;][&#39;hits&#39;]; } return $this-&gt;render(&#39;search-app.html.twig&#39;, [ &#39;searchTerm&#39; =&gt; $searchTerm, &#39;searchResults&#39; =&gt; $searchResults ]); } private function doSearch($searchTerm) { $elastic_host_info = [ $_ENV[&#39;ELASTIC_HOST&#39;], $_ENV[&#39;ELASTIC_PORT&#39;] ]; $elasticSearchClient = ClientBuilder::create()-&gt;setHosts($elastic_host_info)-&gt;build(); $searchParams[&#39;index&#39;] = &#39;screening-room-index&#39;; // which index to search $searchParams[&#39;body&#39;][&#39;query&#39;][&#39;simple_query_string&#39;][&#39;query&#39;] = $searchTerm; // what to search for return $elasticSearchClient-&gt;search($searchParams); } } . . You can find the search-app twig template in search-app/templates/search-app.html.twig. . Let’s search! . Now we should be ready to test our app. Open this URL in your browser http://localhost:8080/public/. You should see a search bar. Type a search term and hit Enter. Depending on the search term, you should get results like the ones below: . . . Previous: The search app (part 1) Next: Searching multiple indexes .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/search-app-2/",
    "relUrl": "/search-app-2/"
  }
  ,"9": {
    "title": "Searching multiple indexes",
    "content": "Searching multiple indexes . We can search multiple indexes in Elasticsearch. Let&#39;s ingest the Railroad Maps, 1828 to 1900 collection from the Library of Congress into the Elasticsearch cluster. Run the following command from the console: . $ cd site/wwwroot/ $ php bin/console app:ingest-data &#39;https://www.loc.gov/collections/railroad-maps-1828-to-1900/?fo=json&#39; &#39;railroad-maps-index&#39; . . Let&#39;s verify that the new index was added by opening http://localhost:9200/_cat/indices?v in your browser. You should get something similar to this: . health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open screening-room-index Aia1GChwQKOizP1VOLV46w 1 1 366 0 1.5mb 798kb green open railroad-maps-index kaGevN-qTNSRA6fWCSVeag 1 1 635 0 2.1mb 1mb . . We need to tell our app to search in both indexes. We do this by adding the new index to the searchParams array of the doSearch() function in the SearchController class. The function should look like this: . # search-app/src/Controller/SearchController.php private function doSearch($searchTerm) { $elastic_host_info = [ $_ENV[&#39;ELASTIC_HOST&#39;], $_ENV[&#39;ELASTIC_PORT&#39;] ]; $elasticSearchClient = ClientBuilder::create()-&gt;setHosts($elastic_host_info)-&gt;build(); $searchParams[&#39;index&#39;] = &#39;screening-room-index,railroad-maps-index&#39;; // which index to search $searchParams[&#39;body&#39;][&#39;query&#39;][&#39;simple_query_string&#39;][&#39;query&#39;] = $searchTerm; // what to search for return $elasticSearchClient-&gt;search($searchParams); } . . &lt;Let’s also output in our search results the name of the index the result belongs to. Add the following code after line 39 in the search-app.html.twig template . # search-app/src/Controller/SearchController.php &lt;p&gt;Index name: {{ result._index }}&lt;/p&gt; . . Now if you do a search, you should get results from both indexes. . . Previous: The search app (part 2) Next: The Dev Tools Console .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/searching-multiple-indexes/",
    "relUrl": "/searching-multiple-indexes/"
  }
  ,"10": {
    "title": "Useful links",
    "content": "Useful links . Thank you for participating in this workshop. Below is a list of links to the documentation of the different technologies that were covered in the workshop. . Docker documentation | Docker Labs | Symfony documentation | Elasticsearch Reference | Elasticsearch DSL | Elasticsearch Clients | Kibana documentation | Getting started with Elasticsearch security | . Have a great Code4Lib 2020! . . Previous: Dev Tools Console .",
    "url": "https://umiamilibraries.github.io/code4lib2020-get-results-es/useful-links/",
    "relUrl": "/useful-links/"
  }
  
}